{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Group Members: Jaymee Hyppolite, Ashutosh Pandey, Timothy Chew, Shashwat Singh"
      ],
      "metadata": {
        "id": "QgbkPexwGw2w"
      },
      "id": "QgbkPexwGw2w"
    },
    {
      "cell_type": "markdown",
      "id": "f6f42319-3cf6-47b9-9c5d-9d755ecf691e",
      "metadata": {
        "id": "f6f42319-3cf6-47b9-9c5d-9d755ecf691e"
      },
      "source": [
        "### 1.Name of Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e9bc574-a9c5-475f-bd87-4fd397868437",
      "metadata": {
        "id": "4e9bc574-a9c5-475f-bd87-4fd397868437"
      },
      "source": [
        "The Name of the dataset is Alzhimers classification with MRI Images"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2134bcdb-d1a2-4431-a2e1-a8e2a284a430",
      "metadata": {
        "id": "2134bcdb-d1a2-4431-a2e1-a8e2a284a430"
      },
      "source": [
        "### 2.Dataset Description"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd61517b-2938-4fd2-9d96-04912ef8f712",
      "metadata": {
        "id": "bd61517b-2938-4fd2-9d96-04912ef8f712"
      },
      "source": [
        "Alzheimer's is the most common cause of dementia, a general term for memory loss and other cognitive abilities serious enough to interfere with daily life. Alzheimer's disease accounts for 60-80% of dementia cases. Memory loss and confusion are the main symptoms. No cure exists, but medication and management strategies may temporarily improve symptoms. Alzheimer's disease tends to develop slowly and gradually worsens over several years. Eventually, Alzheimer's disease affects most areas of your brain. Memory, thinking, judgment, language, problem-solving, personality and movement can all be affected by the disease.\n",
        "\n",
        "The data consists of MRI images. The data has four classes of images both in training as well as a testing set:\n",
        "\n",
        "**Very Mild Demented (VMD)**\n",
        "\n",
        "VMD is the earliest stage of dementia, and symptoms are often so mild that they may go unnoticed by the person themselves or their loved ones. Some common symptoms of VMD include:\n",
        "\n",
        "* Mild memory loss, especially for recent events\n",
        "* Difficulty concentrating or making decisions\n",
        "* Subtle changes in personality or behavior\n",
        "\n",
        "For example, a person with VMD might:\n",
        "\n",
        "* Forget where they put their keys or glasses\n",
        "* Have trouble remembering what they just ate for dinner\n",
        "* Get lost in a familiar place\n",
        "* Have difficulty following conversations or completing tasks\n",
        "* Become more withdrawn or irritable\n",
        "\n",
        "---\n",
        "**Mild Demented (MD)**\n",
        "\n",
        "At this stage, dementia symptoms become more noticeable and may interfere with daily activities. Some common symptoms of MD include:\n",
        "\n",
        "* More significant memory loss, including forgetting important dates or events\n",
        "* Difficulty following conversations or completing tasks\n",
        "* Changes in mood or behavior, such as becoming more withdrawn or irritable\n",
        "* Difficulty with problem-solving or abstract thinking Difficulty with spatial orientation\n",
        "\n",
        "For example, a person with MD might:\n",
        "\n",
        "* Forget the names of close friends or family members\n",
        "* Have trouble remembering how to get to familiar places\n",
        "* Get lost in their own home\n",
        "* Have difficulty managing their finances or paying bills\n",
        "* Become more aggressive or paranoid\n",
        "---\n",
        "**Moderate Demented (MoD)**\n",
        "\n",
        "At this stage, dementia symptoms become severe and make it difficult for the person to live independently. Some common symptoms of MoD include:\n",
        "\n",
        "* Significant memory loss and confusion\n",
        "* Difficulty speaking or understanding language\n",
        "* Difficulty with basic activities of daily living, such as bathing or dressing\n",
        "* Changes in personality and behavior, such as becoming more aggressive or paranoid\n",
        "* Hallucinations or delusions\n",
        "\n",
        "For example, a person with MoD might:\n",
        "\n",
        "* Not recognize their own family members\n",
        "* Have difficulty communicating their needs\n",
        "* Need help with all aspects of daily living\n",
        "* Become more restless or agitated\n",
        "* Experience hallucinations or delusions\n",
        "---\n",
        "**Non-Demented (ND)**\n",
        "\n",
        "This is the term used to describe people who do not have dementia.\n",
        "\n",
        "It is important to note that dementia is a progressive disease, so symptoms will worsen over time. However, the rate of progression varies from person to person. Some people may experience a rapid decline in their cognitive abilities, while others may progress more slowly.\n",
        "\n",
        "It is also important to note that there is no one-size-fits-all presentation of dementia. Symptoms can vary depending on the type of dementia, the stage of the disease, and the individual.\n",
        "\n",
        "In addition to the symptoms listed above, there are a number of other potential signs of dementia, such as:\n",
        "\n",
        "Difficulty with coordination\n",
        "* Changes in sleep patterns\n",
        "* Loss of appetite\n",
        "* Weight loss\n",
        "* Urinary incontinence\n",
        "* Fecal incontinence\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LnreQ_W2xCLS"
      },
      "id": "LnreQ_W2xCLS"
    },
    {
      "cell_type": "markdown",
      "id": "b4f51e6c-c2e3-4756-8ad8-6dc3aabe934e",
      "metadata": {
        "id": "b4f51e6c-c2e3-4756-8ad8-6dc3aabe934e"
      },
      "source": [
        "### 3.Data Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "27cbaf5a-7ec5-44b2-8c7e-823cf77ca709",
      "metadata": {
        "id": "27cbaf5a-7ec5-44b2-8c7e-823cf77ca709"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "#import keras_cv\n",
        "from tensorflow.data import AUTOTUNE\n",
        "import tensorflow.keras as keras\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from tensorflow.keras.layers import (\n",
        "    RandomBrightness, RandomZoom, RandomFlip,\n",
        "    Input, Conv2D, BatchNormalization, MaxPool2D, Dropout, Flatten, Dense\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "3958a9a0-9b55-4005-a85e-7da91d289f85",
      "metadata": {
        "id": "3958a9a0-9b55-4005-a85e-7da91d289f85",
        "outputId": "424dc113-38c5-45c4-cd8c-42a73cca100d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-fa077ad83d64>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimage_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m176\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m208\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m train_data = tf.keras.preprocessing.image_dataset_from_directory(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;34mr'C:/Users/jayme/Downloads/archive (3)/Alzheimer_s Dataset/train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcolor_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/image_dataset.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     image_paths, labels, class_names = dataset_utils.index_directory(\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/dataset_utils.py\u001b[0m in \u001b[0;36mindex_directory\u001b[0;34m(directory, labels, formats, class_names, shuffle, seed, follow_links)\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0msubdirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mlist_directory_v2\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    766\u001b[0m   \"\"\"\n\u001b[1;32m    767\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m     raise errors.NotFoundError(\n\u001b[0m\u001b[1;32m    769\u001b[0m         \u001b[0mnode_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0mop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Could not find directory C:/Users/jayme/Downloads/archive (3)/Alzheimer_s Dataset/train"
          ]
        }
      ],
      "source": [
        "class_names = ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented']\n",
        "image_size = (176,208)\n",
        "\n",
        "train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    r'C:/Users/jayme/Downloads/archive (3)/Alzheimer_s Dataset/train',\n",
        "    color_mode = 'grayscale',\n",
        "    class_names = class_names,\n",
        "    image_size = image_size,\n",
        "    label_mode = 'categorical',\n",
        "    batch_size = 10000\n",
        ")\n",
        "\n",
        "val_data = tf.keras.utils.image_dataset_from_directory(\n",
        "     r'C:/Users/jayme/Downloads/archive (3)/Alzheimer_s Dataset/test',\n",
        "    color_mode = 'grayscale',\n",
        "    class_names = class_names,\n",
        "    image_size = image_size,\n",
        "    label_mode = 'categorical',\n",
        "    batch_size = 10000\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37eef52b-0578-4479-ab9f-0ebe134c0be9",
      "metadata": {
        "id": "37eef52b-0578-4479-ab9f-0ebe134c0be9"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = train_data.as_numpy_iterator().next()\n",
        "X_val, y_val = val_data.as_numpy_iterator().next()\n",
        "\n",
        "del train_data\n",
        "del val_data\n",
        "\n",
        "X = np.concatenate([X_train,X_val],axis=0)\n",
        "y = np.concatenate([y_train,y_val],axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90047686-f77a-4893-b595-44519f79bcca",
      "metadata": {
        "id": "90047686-f77a-4893-b595-44519f79bcca"
      },
      "outputs": [],
      "source": [
        "def plot_imbalance(y):\n",
        "    class_totals = pd.Series([0,0,0,0], index = class_names)\n",
        "    y_sparse = np.argmax(y, axis = -1)\n",
        "    for i,class_name in enumerate(class_names):\n",
        "        total = np.sum(y_sparse == i)\n",
        "        class_totals[class_name] = total\n",
        "    class_totals.plot.bar()\n",
        "\n",
        "plot_imbalance(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75420fe9-0737-4ff9-b0ff-cd62d0d9d658",
      "metadata": {
        "id": "75420fe9-0737-4ff9-b0ff-cd62d0d9d658"
      },
      "source": [
        "### 4.Data Representation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afc52783-8de0-4c15-91fe-1bd62a737bda",
      "metadata": {
        "id": "afc52783-8de0-4c15-91fe-1bd62a737bda"
      },
      "outputs": [],
      "source": [
        "def show_images(X,y, random = True):\n",
        "    \"\"\"\n",
        "    Input: An image list\n",
        "    Output: Displays a grid of 9 images with lables\n",
        "    \"\"\"\n",
        "\n",
        "    labels =dict(zip([0,1,2,3], class_names))\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for i in range(9):\n",
        "        if random:\n",
        "            idx = np.random.randint(0,y.shape[0])\n",
        "        else:\n",
        "            idx = i\n",
        "        x = X[idx]\n",
        "        label = y[idx]\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(x, cmap = 'gray')\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(\"Class:{}\".format(labels[np.argmax(label)]))\n",
        "\n",
        "# Display Train Images\n",
        "show_images(X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb7210ef-97b0-4b82-bd32-e2b86a1e8b08",
      "metadata": {
        "id": "cb7210ef-97b0-4b82-bd32-e2b86a1e8b08"
      },
      "outputs": [],
      "source": [
        "def plot_brightness(X,y):\n",
        "    brightness = []\n",
        "\n",
        "    for image, label in zip(X,y):\n",
        "        brightness.append(np.mean(image))\n",
        "\n",
        "    plt.figure(figsize = (15,5))\n",
        "    plt.subplot(1,2,1)\n",
        "    sns.histplot(brightness)\n",
        "    plt.subplot(1,2,2)\n",
        "    sns.boxplot(brightness)\n",
        "\n",
        "plot_brightness(X,y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mQhZ7W1KPE4u"
      },
      "id": "mQhZ7W1KPE4u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0Na2zVbRPTwb"
      },
      "id": "0Na2zVbRPTwb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.Comment on the Labeling of the Data Set"
      ],
      "metadata": {
        "id": "TZt-EjYqpZgI"
      },
      "id": "TZt-EjYqpZgI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The labeling of the dataset is straightforward. There are 4 classes: non demented, very mild demented, mild demented, and moderate demented. The images are further split up into augmented and originals, which refers to the original dataset and the new augmented images the author added in."
      ],
      "metadata": {
        "id": "jb-HHIr1rPyN"
      },
      "id": "jb-HHIr1rPyN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.Formulation of problem/problem(s)"
      ],
      "metadata": {
        "id": "MH3tsxjCqRu6"
      },
      "id": "MH3tsxjCqRu6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We plan to try various models to build a classifier for these images and think that one of particular interest is the Convolutional Neural Network. This should prove to be an effective way of classifying these images into their respective classes."
      ],
      "metadata": {
        "id": "Xv50YiSgrgry"
      },
      "id": "Xv50YiSgrgry"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}